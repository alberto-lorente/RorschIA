{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll try svm-tfidf on the dataset.\n",
    "\n",
    "Here, we start by importing the datasets (csv or tsv format) we plan to use. Here I use a manualy fused dataset cause I'm the only morron not able to find a way to add the value of one column to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Answer (English)</th>\n",
       "      <th>Contenu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Me it reminds me of a night butterfly with th...</td>\n",
       "      <td>(A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A person on each side (inevitably, it is symme...</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A saucepan on a gas from… camping. The gas sto...</td>\n",
       "      <td>Obj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Answer (English) Contenu\n",
       "0   Me it reminds me of a night butterfly with th...     (A)\n",
       "1  A person on each side (inevitably, it is symme...       H\n",
       "2  A saucepan on a gas from… camping. The gas sto...     Obj\n",
       "3                                                NaN     NaN\n",
       "4                                                NaN     NaN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rap_dataset IS NOT GOOD, no actual responces\n",
    "\n",
    "#data=pd.read_csv('data/rap_dataset.tsv', sep='\\t') #Use this one for TSV format\n",
    "data=pd.read_csv('data/bible_abel_fused_content.csv') #This one CSV format\n",
    "\n",
    "#data\n",
    "data.head() #print the head (5first line) of the dataset to look at it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now check the dataset (important if you don't know it already, here I just check the columns names because we will select a couple of them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Answer (English)', 'Contenu'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns) #print the columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we choose the column we will use. Here I use Contenu, but you can replace it by Localisation for exemple if you use the global dataset. Here well we don't really need the Preparation of the dataset, just to drop the NaN variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test Contenu\n",
    "\n",
    "#Preparing the dataset\n",
    "df=data[[\"Answer (English)\",\"Contenu\"]] #we select the 2 columns we want.\n",
    "df1=df.dropna()#we drop the line with NaN in it. If we don't, the model won't work.\n",
    "\n",
    "text=np.array(df1['Answer (English)']) #we create a NumPy array with the text/answer\n",
    "labels=np.array(df1['Contenu']) #other array for the coding of this answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the dataset (train/test size)\n",
    "\n",
    "here I split the dataset in test and train variables. You can change the \"test_size\" variable to change the ratio of training and testing data. 0.1 mean the test size is 10% of the total dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(text,labels,test_size=0.01,random_state=11) #Change test_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorizing (can modify parameters for TfidfVectorizer)\n",
    "\n",
    "This is the hard part. Vectorisation is, well we turn the text into numbers. We have \"df\" things, I don't remember what they do. I think they make sure useless but omnipresent words like \"a\", \"the\"... are a bit ignored. Ngram range is the range of Ngrams we take. Here, it's unigram to trigrams (on word Ngram to 3 word Ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer=TfidfVectorizer(min_df=2,max_df=0.3,ngram_range=(1,3)) #change parameter\n",
    "x_train_tfidf=tf_vectorizer.fit_transform(x_train)\n",
    "x_test_tfidf=tf_vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the data and getting test score\n",
    "\n",
    "Now you just run this cell. It train and give you the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.LinearSVC(dual=True, max_iter=1000)\n",
    "clf.fit(x_train_tfidf, y_train)\n",
    "\n",
    "clf.score(x_test_tfidf,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Def classify func for predicting a text\n",
    "\n",
    "Here is testing. First cell define a method to test a string and give you the prediction of the model\n",
    "\n",
    "second cell you call the method. Just change the string to what you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(article_text):\n",
    "    global clf\n",
    "    global tf_vectorizer\n",
    "    global data\n",
    "    article=tf_vectorizer.transform([article_text])\n",
    "    \n",
    "    return clf.predict(article)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(H)'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(\"an eye\") #change string here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Small try : Finding the best test_size\n",
    "\n",
    "random state 1 : 0.08 give 0.16\n",
    "\n",
    "random state 2 : 0.05 give 0.25 (same for random state 4)\n",
    "\n",
    "random state 8 : 0.03 and 0.04 give 0.33 (same 11)\n",
    "\n",
    "random state 11 : 0.01 give 1.0 (overfitting), 0.02 and 0.05 give 0.5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 1.0\n",
      "0.02 0.5\n",
      "0.03 0.3333333333333333\n",
      "0.04 0.3333333333333333\n",
      "0.05 0.5\n",
      "0.060000000000000005 0.2\n",
      "0.07 0.2\n",
      "0.08 0.16666666666666666\n",
      "0.09 0.14285714285714285\n",
      "0.09999999999999999 0.14285714285714285\n",
      "0.10999999999999999 0.125\n",
      "0.11999999999999998 0.1111111111111111\n",
      "0.12999999999999998 0.1111111111111111\n",
      "0.13999999999999999 0.1\n",
      "0.15 0.09090909090909091\n",
      "0.16 0.09090909090909091\n",
      "0.17 0.16666666666666666\n",
      "0.18000000000000002 0.15384615384615385\n",
      "0.19000000000000003 0.15384615384615385\n"
     ]
    }
   ],
   "source": [
    "ts=0.01\n",
    "results=[]\n",
    "\n",
    "while ts<0.2:\n",
    "    x_train,x_test,y_train,y_test=train_test_split(text,labels,test_size=ts, random_state=11)\n",
    "\n",
    "    tf_vectorizer=TfidfVectorizer(min_df=2,max_df=0.3,ngram_range=(1,3))\n",
    "    x_train_tfidf=tf_vectorizer.fit_transform(x_train)\n",
    "    x_test_tfidf=tf_vectorizer.transform(x_test)\n",
    "\n",
    "    clf = svm.LinearSVC(dual=True, max_iter=1000)\n",
    "    clf.fit(x_train_tfidf, y_train)\n",
    "\n",
    "    a=clf.score(x_test_tfidf,y_test)\n",
    "    print(ts,a)  \n",
    "    results.append(a)  \n",
    "    ts=ts+0.01"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
